{"ast":null,"code":"// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../../resource.mjs\";\nimport { isRequestOptions } from \"../../../core.mjs\";\nimport { AssistantStream } from \"../../../lib/AssistantStream.mjs\";\nimport * as MessagesAPI from \"./messages.mjs\";\nimport * as RunsAPI from \"./runs/runs.mjs\";\nexport class Threads extends APIResource {\n  constructor() {\n    super(...arguments);\n    this.runs = new RunsAPI.Runs(this._client);\n    this.messages = new MessagesAPI.Messages(this._client);\n  }\n  create(body = {}, options) {\n    if (isRequestOptions(body)) {\n      return this.create({}, body);\n    }\n    return this._client.post('/threads', {\n      body,\n      ...options,\n      headers: {\n        'OpenAI-Beta': 'assistants=v2',\n        ...options?.headers\n      }\n    });\n  }\n  /**\n   * Retrieves a thread.\n   */\n  retrieve(threadId, options) {\n    return this._client.get(`/threads/${threadId}`, {\n      ...options,\n      headers: {\n        'OpenAI-Beta': 'assistants=v2',\n        ...options?.headers\n      }\n    });\n  }\n  /**\n   * Modifies a thread.\n   */\n  update(threadId, body, options) {\n    return this._client.post(`/threads/${threadId}`, {\n      body,\n      ...options,\n      headers: {\n        'OpenAI-Beta': 'assistants=v2',\n        ...options?.headers\n      }\n    });\n  }\n  /**\n   * Delete a thread.\n   */\n  del(threadId, options) {\n    return this._client.delete(`/threads/${threadId}`, {\n      ...options,\n      headers: {\n        'OpenAI-Beta': 'assistants=v2',\n        ...options?.headers\n      }\n    });\n  }\n  createAndRun(body, options) {\n    return this._client.post('/threads/runs', {\n      body,\n      ...options,\n      headers: {\n        'OpenAI-Beta': 'assistants=v2',\n        ...options?.headers\n      },\n      stream: body.stream ?? false\n    });\n  }\n  /**\n   * A helper to create a thread, start a run and then poll for a terminal state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndRunPoll(body, options) {\n    const run = await this.createAndRun(body, options);\n    return await this.runs.poll(run.thread_id, run.id, options);\n  }\n  /**\n   * Create a thread and stream the run back\n   */\n  createAndRunStream(body, options) {\n    return AssistantStream.createThreadAssistantStream(body, this._client.beta.threads, options);\n  }\n}\n(function (Threads) {\n  Threads.Runs = RunsAPI.Runs;\n  Threads.RunsPage = RunsAPI.RunsPage;\n  Threads.Messages = MessagesAPI.Messages;\n  Threads.MessagesPage = MessagesAPI.MessagesPage;\n})(Threads || (Threads = {}));\n//# sourceMappingURL=threads.mjs.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}