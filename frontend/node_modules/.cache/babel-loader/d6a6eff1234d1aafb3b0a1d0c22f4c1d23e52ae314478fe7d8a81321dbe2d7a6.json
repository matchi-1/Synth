{"ast":null,"code":"import { ReadableStream } from \"./_shims/index.mjs\";\nimport { OpenAIError } from \"./error.mjs\";\nimport { APIError } from 'openai/error';\nexport class Stream {\n  constructor(iterator, controller) {\n    this.iterator = iterator;\n    this.controller = controller;\n  }\n  static fromSSEResponse(response, controller) {\n    let consumed = false;\n    async function* iterator() {\n      if (consumed) {\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const sse of _iterSSEMessages(response, controller)) {\n          if (done) continue;\n          if (sse.data.startsWith('[DONE]')) {\n            done = true;\n            continue;\n          }\n          if (sse.event === null) {\n            let data;\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n            if (data && data.error) {\n              throw new APIError(undefined, data.error, undefined, undefined);\n            }\n            yield data;\n          } else {\n            let data;\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n            // TODO: Is this where the error should be thrown?\n            if (sse.event == 'error') {\n              throw new APIError(undefined, data.error, data.message, undefined);\n            }\n            yield {\n              event: sse.event,\n              data: data\n            };\n          }\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (e instanceof Error && e.name === 'AbortError') return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n    return new Stream(iterator, controller);\n  }\n  /**\n   * Generates a Stream from a newline-separated ReadableStream\n   * where each item is a JSON value.\n   */\n  static fromReadableStream(readableStream, controller) {\n    let consumed = false;\n    async function* iterLines() {\n      const lineDecoder = new LineDecoder();\n      const iter = readableStreamAsyncIterable(readableStream);\n      for await (const chunk of iter) {\n        for (const line of lineDecoder.decode(chunk)) {\n          yield line;\n        }\n      }\n      for (const line of lineDecoder.flush()) {\n        yield line;\n      }\n    }\n    async function* iterator() {\n      if (consumed) {\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const line of iterLines()) {\n          if (done) continue;\n          if (line) yield JSON.parse(line);\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (e instanceof Error && e.name === 'AbortError') return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n    return new Stream(iterator, controller);\n  }\n  [Symbol.asyncIterator]() {\n    return this.iterator();\n  }\n  /**\n   * Splits the stream into two streams which can be\n   * independently read from at different speeds.\n   */\n  tee() {\n    const left = [];\n    const right = [];\n    const iterator = this.iterator();\n    const teeIterator = queue => {\n      return {\n        next: () => {\n          if (queue.length === 0) {\n            const result = iterator.next();\n            left.push(result);\n            right.push(result);\n          }\n          return queue.shift();\n        }\n      };\n    };\n    return [new Stream(() => teeIterator(left), this.controller), new Stream(() => teeIterator(right), this.controller)];\n  }\n  /**\n   * Converts this stream to a newline-separated ReadableStream of\n   * JSON stringified values in the stream\n   * which can be turned back into a Stream with `Stream.fromReadableStream()`.\n   */\n  toReadableStream() {\n    const self = this;\n    let iter;\n    const encoder = new TextEncoder();\n    return new ReadableStream({\n      async start() {\n        iter = self[Symbol.asyncIterator]();\n      },\n      async pull(ctrl) {\n        try {\n          const {\n            value,\n            done\n          } = await iter.next();\n          if (done) return ctrl.close();\n          const bytes = encoder.encode(JSON.stringify(value) + '\\n');\n          ctrl.enqueue(bytes);\n        } catch (err) {\n          ctrl.error(err);\n        }\n      },\n      async cancel() {\n        await iter.return?.();\n      }\n    });\n  }\n}\nexport async function* _iterSSEMessages(response, controller) {\n  if (!response.body) {\n    controller.abort();\n    throw new OpenAIError(`Attempted to iterate over a response with no body`);\n  }\n  const sseDecoder = new SSEDecoder();\n  const lineDecoder = new LineDecoder();\n  const iter = readableStreamAsyncIterable(response.body);\n  for await (const sseChunk of iterSSEChunks(iter)) {\n    for (const line of lineDecoder.decode(sseChunk)) {\n      const sse = sseDecoder.decode(line);\n      if (sse) yield sse;\n    }\n  }\n  for (const line of lineDecoder.flush()) {\n    const sse = sseDecoder.decode(line);\n    if (sse) yield sse;\n  }\n}\n/**\n * Given an async iterable iterator, iterates over it and yields full\n * SSE chunks, i.e. yields when a double new-line is encountered.\n */\nasync function* iterSSEChunks(iterator) {\n  let data = new Uint8Array();\n  for await (const chunk of iterator) {\n    if (chunk == null) {\n      continue;\n    }\n    const binaryChunk = chunk instanceof ArrayBuffer ? new Uint8Array(chunk) : typeof chunk === 'string' ? new TextEncoder().encode(chunk) : chunk;\n    let newData = new Uint8Array(data.length + binaryChunk.length);\n    newData.set(data);\n    newData.set(binaryChunk, data.length);\n    data = newData;\n    let patternIndex;\n    while ((patternIndex = findDoubleNewlineIndex(data)) !== -1) {\n      yield data.slice(0, patternIndex);\n      data = data.slice(patternIndex);\n    }\n  }\n  if (data.length > 0) {\n    yield data;\n  }\n}\nfunction findDoubleNewlineIndex(buffer) {\n  // This function searches the buffer for the end patterns (\\r\\r, \\n\\n, \\r\\n\\r\\n)\n  // and returns the index right after the first occurrence of any pattern,\n  // or -1 if none of the patterns are found.\n  const newline = 0x0a; // \\n\n  const carriage = 0x0d; // \\r\n  for (let i = 0; i < buffer.length - 2; i++) {\n    if (buffer[i] === newline && buffer[i + 1] === newline) {\n      // \\n\\n\n      return i + 2;\n    }\n    if (buffer[i] === carriage && buffer[i + 1] === carriage) {\n      // \\r\\r\n      return i + 2;\n    }\n    if (buffer[i] === carriage && buffer[i + 1] === newline && i + 3 < buffer.length && buffer[i + 2] === carriage && buffer[i + 3] === newline) {\n      // \\r\\n\\r\\n\n      return i + 4;\n    }\n  }\n  return -1;\n}\nclass SSEDecoder {\n  constructor() {\n    this.event = null;\n    this.data = [];\n    this.chunks = [];\n  }\n  decode(line) {\n    if (line.endsWith('\\r')) {\n      line = line.substring(0, line.length - 1);\n    }\n    if (!line) {\n      // empty line and we didn't previously encounter any messages\n      if (!this.event && !this.data.length) return null;\n      const sse = {\n        event: this.event,\n        data: this.data.join('\\n'),\n        raw: this.chunks\n      };\n      this.event = null;\n      this.data = [];\n      this.chunks = [];\n      return sse;\n    }\n    this.chunks.push(line);\n    if (line.startsWith(':')) {\n      return null;\n    }\n    let [fieldname, _, value] = partition(line, ':');\n    if (value.startsWith(' ')) {\n      value = value.substring(1);\n    }\n    if (fieldname === 'event') {\n      this.event = value;\n    } else if (fieldname === 'data') {\n      this.data.push(value);\n    }\n    return null;\n  }\n}\n/**\n * A re-implementation of httpx's `LineDecoder` in Python that handles incrementally\n * reading lines from text.\n *\n * https://github.com/encode/httpx/blob/920333ea98118e9cf617f246905d7b202510941c/httpx/_decoders.py#L258\n */\nclass LineDecoder {\n  constructor() {\n    this.buffer = [];\n    this.trailingCR = false;\n  }\n  decode(chunk) {\n    let text = this.decodeText(chunk);\n    if (this.trailingCR) {\n      text = '\\r' + text;\n      this.trailingCR = false;\n    }\n    if (text.endsWith('\\r')) {\n      this.trailingCR = true;\n      text = text.slice(0, -1);\n    }\n    if (!text) {\n      return [];\n    }\n    const trailingNewline = LineDecoder.NEWLINE_CHARS.has(text[text.length - 1] || '');\n    let lines = text.split(LineDecoder.NEWLINE_REGEXP);\n    // if there is a trailing new line then the last entry will be an empty\n    // string which we don't care about\n    if (trailingNewline) {\n      lines.pop();\n    }\n    if (lines.length === 1 && !trailingNewline) {\n      this.buffer.push(lines[0]);\n      return [];\n    }\n    if (this.buffer.length > 0) {\n      lines = [this.buffer.join('') + lines[0], ...lines.slice(1)];\n      this.buffer = [];\n    }\n    if (!trailingNewline) {\n      this.buffer = [lines.pop() || ''];\n    }\n    return lines;\n  }\n  decodeText(bytes) {\n    if (bytes == null) return '';\n    if (typeof bytes === 'string') return bytes;\n    // Node:\n    if (typeof Buffer !== 'undefined') {\n      if (bytes instanceof Buffer) {\n        return bytes.toString();\n      }\n      if (bytes instanceof Uint8Array) {\n        return Buffer.from(bytes).toString();\n      }\n      throw new OpenAIError(`Unexpected: received non-Uint8Array (${bytes.constructor.name}) stream chunk in an environment with a global \"Buffer\" defined, which this library assumes to be Node. Please report this error.`);\n    }\n    // Browser\n    if (typeof TextDecoder !== 'undefined') {\n      if (bytes instanceof Uint8Array || bytes instanceof ArrayBuffer) {\n        this.textDecoder ?? (this.textDecoder = new TextDecoder('utf8'));\n        return this.textDecoder.decode(bytes);\n      }\n      throw new OpenAIError(`Unexpected: received non-Uint8Array/ArrayBuffer (${bytes.constructor.name}) in a web platform. Please report this error.`);\n    }\n    throw new OpenAIError(`Unexpected: neither Buffer nor TextDecoder are available as globals. Please report this error.`);\n  }\n  flush() {\n    if (!this.buffer.length && !this.trailingCR) {\n      return [];\n    }\n    const lines = [this.buffer.join('')];\n    this.buffer = [];\n    this.trailingCR = false;\n    return lines;\n  }\n}\n// prettier-ignore\nLineDecoder.NEWLINE_CHARS = new Set(['\\n', '\\r']);\nLineDecoder.NEWLINE_REGEXP = /\\r\\n|[\\n\\r]/g;\n/** This is an internal helper function that's just used for testing */\nexport function _decodeChunks(chunks) {\n  const decoder = new LineDecoder();\n  const lines = [];\n  for (const chunk of chunks) {\n    lines.push(...decoder.decode(chunk));\n  }\n  return lines;\n}\nfunction partition(str, delimiter) {\n  const index = str.indexOf(delimiter);\n  if (index !== -1) {\n    return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];\n  }\n  return [str, '', ''];\n}\n/**\n * Most browsers don't yet have async iterable support for ReadableStream,\n * and Node has a very different way of reading bytes from its \"ReadableStream\".\n *\n * This polyfill was pulled from https://github.com/MattiasBuelens/web-streams-polyfill/pull/122#issuecomment-1627354490\n */\nexport function readableStreamAsyncIterable(stream) {\n  if (stream[Symbol.asyncIterator]) return stream;\n  const reader = stream.getReader();\n  return {\n    async next() {\n      try {\n        const result = await reader.read();\n        if (result?.done) reader.releaseLock(); // release lock when stream becomes closed\n        return result;\n      } catch (e) {\n        reader.releaseLock(); // release lock when stream becomes errored\n        throw e;\n      }\n    },\n    async return() {\n      const cancelPromise = reader.cancel();\n      reader.releaseLock();\n      await cancelPromise;\n      return {\n        done: true,\n        value: undefined\n      };\n    },\n    [Symbol.asyncIterator]() {\n      return this;\n    }\n  };\n}\n//# sourceMappingURL=streaming.mjs.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}